# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fzSgWOrJ9qoDHLHnAzA-YaoTm9vGI_B5
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install streamlit

import streamlit as st
import torch
import numpy as np
import pandas as pd
from transformers import AutoModelForSequenceClassification, AutoTokenizer
# Import plotting library (e.g., Plotly for interactivity)
import plotly.express as px
# Note: For SHAP/LIME, you would need to install and import the respective library (e.g., from transformers_interpret import SequenceClassificationExplainer)

# --- CONFIGURATION ---
MODEL_PATH = '/content/drive/MyDrive/Project for cv 1/final_model_saved_4class_training' # The folder where your model is saved
LABEL_MAP = {0: "1 Star üò°", 1: "2 Stars üò†", 2: "3 Stars üòê", 3: "4 Stars üòä", 4: "5 Stars üî•"}
MAX_LENGTH = 128
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# --- 1. Load Model and Tokenizer (Cached for Speed) ---

@st.cache_resource
def load_model():
    """Loads the fine-tuned RoBERTa model and tokenizer once."""
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
    model.to(DEVICE)
    model.eval() # Set model to evaluation mode
    return tokenizer, model

tokenizer, model = load_model()

# --- 2. Prediction Function ---

def predict_sentiment(review_text):
    """Tokenizes input and gets prediction logits from the model."""
    inputs = tokenizer(review_text, return_tensors="pt",
                       truncation=True, padding='max_length',
                       max_length=MAX_LENGTH)

    # Move inputs to the correct device
    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)

    # Softmax to get probabilities
    probabilities = torch.softmax(outputs.logits, dim=1).cpu().squeeze()

    # Get the predicted star rating (index + 1)
    predicted_index = torch.argmax(probabilities).item()
    predicted_star = LABEL_MAP[predicted_index]

    return predicted_star, probabilities.numpy()

# --- 3. Streamlit UI Layout ---

st.set_page_config(layout="wide", page_title="Yelp Sentiment Deep Dive")
st.title("üåü Advanced 5-Class Sentiment Deep Dive")
st.markdown("Analyze a Yelp review using the **RoBERTa Transformer** model, optimized with **Weighted Loss**.")
st.divider()

# Input area
review_input = st.text_area("Paste a Yelp Review Here:",
                            "The food was good, but the waiter forgot our order and the prices were too high for the portion size.",
                            height=150)

# The GO button
if st.button("Analyze Review", type="primary"):

    if not review_input.strip():
        st.warning("Please enter a review to analyze.")
    else:
        # Run Prediction
        predicted_star, probabilities = predict_sentiment(review_input)

        col1, col2 = st.columns([1, 2])

        # COLUMN 1: Main Result
        with col1:
            st.subheader("Predicted Star Rating")
            st.success(f"## {predicted_star}")
            st.markdown(f"*(Confidence: {probabilities[torch.argmax(torch.tensor(probabilities))]:.2f})*")

        # COLUMN 2: Confidence Chart
        with col2:
            st.subheader("Model Confidence Distribution")

            # Create a DataFrame for the bar chart
            prob_df = pd.DataFrame({
                'Rating': list(LABEL_MAP.values()),
                'Probability': probabilities
            })

            # Use Plotly for a visually appealing and interactive bar chart
            fig = px.bar(prob_df, x='Rating', y='Probability',
                         color='Probability', color_continuous_scale=px.colors.sequential.Sunset,
                         height=300)
            fig.update_layout(xaxis={'categoryorder':'array', 'categoryarray': list(LABEL_MAP.values())})
            st.plotly_chart(fig, use_container_width=True)

        st.divider()

        # --- Advanced Feature: Interpretability (LIME/SHAP) ---
        st.subheader("üîç Local Interpretability (Why this Prediction?)")
        st.info("You would integrate a tool like SHAP or LIME here to visualize token importance.")
        # E.g., st_shap(explainer.explain_instance(review_input))
        st.markdown("**Example Display:** Words like 'forgot' and 'too high' pulled the score down, while 'food was good' contributed positively.")

